import re
import json
import urllib.parse
from fastapi import APIRouter, HTTPException, UploadFile, File, Query, Request, Depends
from typing import List, Optional
from pathlib import Path
from pydantic import BaseModel
from collections import Counter
from fastapi.responses import StreamingResponse
from program.managers.sse_manager import sse_manager
from loguru import logger
from pathlib import Path
from src.services.fonctions_arrs import RadarrService, SonarrService
from fastapi import status
import asyncio
import httpx

sonarr = SonarrService()

router = APIRouter(prefix="/symlinks", tags=["Symlinks"])

symlink_store = []

class ConfigModel(BaseModel):
    links_dirs: List[str]  # Liste de rÃ©pertoires pour links_dir
    mount_dirs: List[str]  # Liste de rÃ©pertoires pour mount_dir
    radarr_api_key: str
    sonarr_api_key: str

CONFIG_PATH = Path("data/config.json")

class SymlinkItem(BaseModel):
    symlink: str
    target: str
    ref_count: int

def load_config():
    if CONFIG_PATH.exists():
        try:
            return json.loads(CONFIG_PATH.read_text())
        except json.JSONDecodeError:
            logger.warning("Fichier de configuration JSON invalide, utilisation des valeurs par dÃ©faut")
    return {"links_dirs": ["/links"], "mount_dirs": ["/mnt/rd"]}

def save_config(data):
    CONFIG_PATH.parent.mkdir(exist_ok=True, parents=True)
    with open(CONFIG_PATH, "w") as f:
        json.dump(data, f, indent=2)
    logger.success("Configuration enregistrÃ©e")

def scan_symlinks():
    config = load_config()
    logger.debug(f"ğŸ§¾ Config chargÃ©e : {config}")

    links_dirs = [Path(d) for d in config["links_dirs"]]
    mount_dirs = [Path(d).resolve() for d in config["mount_dirs"]]

    for links_dir in links_dirs:
        if not links_dir.exists():
            raise RuntimeError(f"Dossier introuvable : {links_dir}")
    for mount_dir in mount_dirs:
        if not mount_dir.exists():
            raise RuntimeError(f"Dossier introuvable : {mount_dir}")

    symlinks_list = []

    for links_dir in links_dirs:
        for symlink_path in links_dir.rglob("*"):
            if symlink_path.is_symlink():
                try:
                    target_path = symlink_path.resolve(strict=True)
                except FileNotFoundError:
                    target_path = symlink_path.resolve(strict=False)

                # ğŸ” Trouver le mount_dir applicable
                matched_mount = None
                for mount_dir in mount_dirs:
                    try:
                        relative_target = target_path.relative_to(mount_dir)
                        matched_mount = mount_dir
                        break
                    except ValueError:
                        continue

                if matched_mount:
                    full_target = str(matched_mount / relative_target)
                else:
                    full_target = str(target_path)

                # ğŸ“¦ DÃ©tection du type (radarr / sonarr)
                lower_symlink = str(symlink_path).lower()
                if "/shows/" in lower_symlink or "/series/" in lower_symlink:
                    symlink_type = "sonarr"
                elif "/movies/" in lower_symlink or "/films/" in lower_symlink:
                    symlink_type = "radarr"
                else:
                    symlink_type = "unknown"

                symlinks_list.append({
                    "symlink": str(symlink_path),
                    "target": full_target,
                    "target_exists": target_path.exists(),
                    "type": symlink_type,
                })

    # ğŸ§® Calcul des ref_count
    target_counts = Counter(item["target"] for item in symlinks_list if item["target_exists"])

    results = []
    for item in symlinks_list:
        ref_count = target_counts.get(item["target"], 0) if item["target_exists"] else 0
        results.append({
            "symlink": item["symlink"],
            "target": item["target"],
            "ref_count": ref_count,
            "type": item["type"],
        })

    logger.success(f"{len(results)} liens symboliques scannÃ©s")
    return results

@router.get("")
def list_symlinks(
    page: int = Query(1, gt=0),
    limit: int = Query(50, gt=0, le=1000),
    search: Optional[str] = None,
    sort: Optional[str] = "symlink",
    order: Optional[str] = "asc",
    orphans: Optional[bool] = False,
    folder: Optional[str] = None,
    all: bool = False  # â¬…ï¸ ajout
):
    if not symlink_store:
        raise HTTPException(status_code=503, detail="Cache vide, lancez un scan d'abord.")

    items = symlink_store.copy()

    # ğŸ”½ Filtre par dossier
    if folder:
        try:
            config = load_config()
            base_dir = Path(config.get("links_dirs", ["/"])[0])
            folder_path = (base_dir / folder).resolve()
            folder_str = str(folder_path)

            items = [i for i in items if i["symlink"].startswith(folder_str)]
        except Exception as e:
            logger.error(f"Erreur filtre folder={folder} : {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"Erreur dossier {folder}")

    # ğŸ” Filtres search et orphelins
    if search:
        search_lower = search.lower()
        items = [i for i in items if search_lower in i["symlink"].lower() or search_lower in i["target"].lower()]

    if orphans:
        items = [i for i in items if i["ref_count"] == 0]

    reverse = order == "desc"
    if sort in {"symlink", "target", "ref_count"}:
        items.sort(key=lambda x: x[sort], reverse=reverse)

    total = len(items)

    if not all:
        start = (page - 1) * limit
        end = start + limit
        paginated = items[start:end]
    else:
        paginated = items  # â¬…ï¸ ignore pagination si all=True

    logger.info(f"âœ… Renvoi du cache mÃ©moire â€” page {page} ({len(paginated)} Ã©lÃ©ments)")

    return {
        "total": total,
        "page": page,
        "limit": limit,
        "data": paginated,
        "orphaned": sum(1 for i in items if i["ref_count"] == 0),
        "unique_targets": len(set(i["target"] for i in items if i["ref_count"] > 0)),
    }

@router.post("/scan")
def trigger_scan():
    try:
        data = scan_symlinks()
        symlink_store.clear()
        symlink_store.extend(data)
        sse_manager.publish_event("symlink_update", json.dumps({"event": "refreshed"}))
        return {"message": "Scan terminÃ©", "count": len(data), "data": data}
    except Exception as e:
        logger.error(f"Erreur scan symlinks: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def clean_movie_name(raw_name: str) -> str:
    """
    Nettoie le nom dâ€™un film :
    - Supprime lâ€™annÃ©e entre parenthÃ¨ses : (1999)
    - Supprime toute balise IMDb mÃªme mal fermÃ©e : {imdb-tt1234567, {imdb-tt12345678}, etc.
    - Supprime les espaces superflus
    """
    # Supprimer lâ€™annÃ©e (ex : (2022))
    cleaned = re.sub(r'\s*\(\d{4}\)', '', raw_name)

    # Supprimer les balises IMDb (mÃªme mal fermÃ©es)
    cleaned = re.sub(r'\s*\{imdb-tt\d{7,8}[^\}]*\}?', '', cleaned)

    return cleaned.strip()

@router.delete("/delete/{symlink_path:path}")
async def delete_symlink(
    symlink_path: str,
    radarr: RadarrService = Depends(RadarrService)
):
    logger.debug("ğŸ”§ DÃ©but de la suppression du symlink")

    decoded_symlink_path = urllib.parse.unquote(symlink_path)
    logger.debug(f"ğŸ“¥ Chemin symlink brut : {symlink_path}")
    logger.debug(f"ğŸ“¥ Chemin symlink dÃ©codÃ© : {decoded_symlink_path}")

    config = load_config()
    links_dirs = [Path(d).resolve() for d in config["links_dirs"]]
    logger.debug(f"ğŸ“ RÃ©pertoires autorisÃ©s (links_dirs) : {links_dirs}")

    full_path = None
    for links_dir in links_dirs:
        candidate = links_dir / decoded_symlink_path
        if candidate.exists() or candidate.is_symlink():
            full_path = candidate
            break

    if not full_path:
        logger.warning(f"âŒ Chemin en dehors des links_dirs : {decoded_symlink_path}")
        raise HTTPException(status_code=400, detail="Chemin invalide ou hors des rÃ©pertoires autorisÃ©s")

    symlink_path = full_path
    logger.debug(f"ğŸ“Œ Chemin absolu reconstruit : {symlink_path}")

    try:
        if not symlink_path.is_symlink():
            logger.warning(f"âš ï¸ Le lien symbolique n'existe pas : {symlink_path}")
            raise HTTPException(status_code=404, detail="Lien symbolique introuvable")

        symlink_path.unlink()
        logger.info(f"ğŸ—‘ï¸ Lien supprimÃ© avec succÃ¨s : {symlink_path}")

        target_path = symlink_path.resolve(strict=False)
        logger.debug(f"ğŸ“ Chemin de la cible (non strict) : {target_path}")

        # ğŸ†• Utilisation du nom du dossier parent
        raw_name = symlink_path.parent.name
        logger.debug(f"ğŸ¬ Nom brut : {raw_name}")

        def clean_movie_title(name: str) -> str:
            name = re.sub(r'\s*\{imdb-tt\d{7,8}[^\}]*\}?', '', name)  # IMDb mal fermÃ©
            name = re.sub(r'\s*\(\d{4}\)', '', name)  # annÃ©e
            return name.strip()

        cleaned_title = clean_movie_title(raw_name)
        logger.debug(f"ğŸ§¼ Titre nettoyÃ© transmis Ã  Radarr : {cleaned_title}")

        logger.debug(f"ğŸ” Recherche du film : {cleaned_title}")
        movie = radarr.get_movie_by_clean_title(cleaned_title)

        if not movie:
            logger.warning(f"â— Aucun film trouvÃ© correspondant Ã  : {cleaned_title}")
            raise HTTPException(status_code=404, detail=f"Aucun film trouvÃ© avec le nom : {cleaned_title}")

        movie_id = movie["id"]
        logger.info(f"ğŸ¯ Film trouvÃ© : {movie['title']} ({movie.get('year')}) â€” ID : {movie_id}")

        try:
            radarr.refresh_movie(movie_id)
            logger.info(f"âœ… RafraÃ®chissement rÃ©ussi pour : {movie['title']}")
        except Exception as e:
            logger.error(f"âŒ Ã‰chec du rafraÃ®chissement : {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"Erreur rafraÃ®chissement : {e}")

        try:
            await asyncio.sleep(2)
            radarr.search_missing_movie(movie_id)
            logger.info(f"ğŸ“¥ Recherche de tÃ©lÃ©chargement lancÃ©e pour : {movie['title']}")
        except Exception as e:
            logger.error(f"âŒ Ã‰chec de la recherche de tÃ©lÃ©chargement : {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"Erreur recherche : {e}")

    except HTTPException as e:
        logger.error(f"ğŸš¨ HTTPException capturÃ©e : {e.detail}")
        raise e
    except Exception as e:
        logger.error("ğŸ’¥ Exception inattendue capturÃ©e", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur interne : {str(e)}")

    logger.info("âœ… Suppression et actions Radarr terminÃ©es")
    return {"message": "Symlink supprimÃ© et traitement Radarr effectuÃ© avec succÃ¨s."}

@router.get("/config", response_model=ConfigModel)
def get_config():
    return load_config()

@router.post("/config", response_model=ConfigModel)
def save_new_config(config: ConfigModel):
    save_config(config.dict())
    return config

@router.get("/events")
async def symlink_sse(request: Request):
    async def event_generator():
        async for event in sse_manager.subscribe("symlink_update"):
            if await request.is_disconnected():
                break
            yield f"data: {event}\n\n"
    return StreamingResponse(event_generator(), media_type="text/event-stream")

@router.get("/folders")
def list_subfolders():
    config = load_config()
    links_dirs = config.get("links_dirs", [])
    root_dir = Path(links_dirs[0]) if links_dirs else None

    if not root_dir or not root_dir.exists():
        raise HTTPException(status_code=500, detail="RÃ©pertoire links_dirs invalide ou manquant")

    try:
        subdirs = [f.name for f in root_dir.iterdir() if f.is_dir()]
        return subdirs
    except Exception as e:
        logger.error(f"Erreur lecture dossiers : {e}")
        raise HTTPException(status_code=500, detail="Erreur lecture des sous-dossiers")

@router.post("/delete_broken")
async def delete_broken_symlinks(
    folder: Optional[str] = None,
    radarr: RadarrService = Depends(RadarrService)
):
    logger.info("ğŸš€ Suppression en masse des symlinks cassÃ©s demandÃ©e")

    if not symlink_store:
        raise HTTPException(status_code=503, detail="Cache vide, lancez un scan d'abord.")

    config = load_config()
    base_links_dir = Path(config.get("links_dirs", ["/"])[0]).resolve()

    # Filtrage initial
    items = symlink_store.copy()
    if folder:
        folder_path = (base_links_dir / folder).resolve()
        items = [i for i in items if i["symlink"].startswith(str(folder_path))]

    # Filtrer uniquement les cassÃ©s
    broken_symlinks = [i for i in items if i["ref_count"] == 0]
    if not broken_symlinks:
        return {"message": "Aucun symlink cassÃ© Ã  supprimer", "deleted": 0}

    logger.info(f"ğŸ” {len(broken_symlinks)} symlinks cassÃ©s Ã  traiter")

    deleted_count = 0
    errors = []

    for item in broken_symlinks:
        try:
            # Reconstruire le chemin complet
            symlink_path = Path(item["symlink"])
            if not symlink_path.is_symlink():
                logger.warning(f"â›” Pas un symlink valide : {symlink_path}")
                continue

            # Supprimer le symlink
            symlink_path.unlink()
            logger.success(f"ğŸ—‘ï¸ SupprimÃ© : {symlink_path}")
            deleted_count += 1

            # Traitement Radarr
            raw_name = symlink_path.parent.name
            cleaned_name = clean_movie_name(raw_name)
            title_without_year = re.sub(r'\s*\(\d{4}\)', '', cleaned_name).strip()
            movie = radarr.get_movie_by_clean_title(title_without_year)

            if not movie:
                logger.warning(f"â— Aucun film trouvÃ© dans Radarr : {title_without_year}")
                continue

            movie_id = movie["id"]
            radarr.refresh_movie(movie_id)
            await asyncio.sleep(2)
            radarr.search_missing_movie(movie_id)
            logger.info(f"ğŸ“¥ Recherche relancÃ©e pour : {movie['title']}")

        except Exception as e:
            error_msg = f"Erreur {item['symlink']}: {str(e)}"
            logger.error(error_msg, exc_info=True)
            errors.append(error_msg)

    # Notification SSE
    sse_manager.publish_event("symlink_update", json.dumps({"event": "refreshed"}))

    return {
        "message": f"{deleted_count} symlinks cassÃ©s supprimÃ©s",
        "deleted": deleted_count,
        "errors": errors
    }

def clean_series_name(raw_name: str) -> str:
    """
    Nettoie le nom de la sÃ©rie :
    - Supprime les balises IMDb mÃªme mal formÃ©es : {imdb-tt1234567}, {imdb-tt1234567, {imdb-tt1234567... etc.
    - Conserve l'annÃ©e entre parenthÃ¨ses si elle existe.
    - Supprime les espaces superflus autour.
    - Nettoie les espaces multiples internes.
    """
    # Supprime tout ce qui ressemble Ã  une balise IMDb, mÃªme mal formÃ©e
    cleaned = re.sub(r'\s*\{imdb-tt\d{7,8}[^\}]*\}?', '', raw_name)

    # Supprime les parenthÃ¨ses vides ou rÃ©sidus (facultatif, mais utile)
    cleaned = re.sub(r'\(\s*\)', '', cleaned)

    # RÃ©duit les espaces multiples
    cleaned = re.sub(r'\s+', ' ', cleaned)

    # Supprime les espaces en trop en dÃ©but/fin
    return cleaned.strip()


@router.delete("/delete-sonarr/{symlink_path:path}")
async def delete_symlink_sonarr(
    symlink_path: str,
    sonarr: SonarrService = Depends(SonarrService)
):
    """
    Supprime un lien symbolique cÃ´tÃ© Sonarr, puis dÃ©clenche le rafraÃ®chissement + recherche dâ€™Ã©pisodes manquants.
    Si le fichier est toujours manquant aprÃ¨s le scan, on supprime tous les symlinks de la saison
    et on appelle l'API delete-sonarr-season.
    """
    logger.debug("ğŸ”§ DÃ©but de la suppression du symlink (Sonarr)")

    # DÃ©codage de lâ€™URL encodÃ©e
    decoded_path = urllib.parse.unquote(symlink_path)
    logger.debug(f"ğŸ“¥ Chemin symlink brut : {symlink_path}")
    logger.debug(f"ğŸ“¥ Chemin symlink dÃ©codÃ© : {decoded_path}")

    # Chargement config
    config = load_config()
    links_dirs = [Path(d).resolve() for d in config["links_dirs"]]
    logger.debug(f"ğŸ“ RÃ©pertoires autorisÃ©s (links_dirs) : {links_dirs}")

    # Recherche du chemin absolu basÃ© sur links_dirs
    symlink_path = None
    for base in links_dirs:
        candidate = base / decoded_path
        logger.debug(f"ğŸ” Test du chemin candidat : {candidate}")
        if candidate.is_symlink() or candidate.exists():
            symlink_path = candidate
            break

    if not symlink_path:
        logger.warning(f"âŒ Chemin en dehors des links_dirs : {decoded_path}")
        raise HTTPException(status_code=400, detail="Chemin invalide ou hors des rÃ©pertoires autorisÃ©s")

    logger.debug(f"ğŸ“Œ Chemin absolu du lien symbolique : {symlink_path}")

    try:
        # VÃ©rification existence
        if not symlink_path.is_symlink():
            logger.warning(f"âš ï¸ Le lien symbolique n'existe pas : {symlink_path}")
            raise HTTPException(status_code=404, detail="Lien symbolique introuvable")

        # Suppression du symlink
        symlink_path.unlink()
        logger.info(f"ğŸ—‘ï¸ Lien supprimÃ© avec succÃ¨s : {symlink_path}")

        # Extraction du dossier de la saison et de la sÃ©rie
        season_dir = symlink_path.parent
        series_dir = season_dir.parent
        logger.debug(f"ğŸ“ Dossier sÃ©rie : {series_dir}")

        series_folder_name = series_dir.name
        logger.debug(f"ğŸ“º Nom brut du dossier sÃ©rie : {series_folder_name}")

        # Nettoyage du nom
        cleaned = re.sub(r'\s*\{imdb-tt\d{7}\}', '', series_folder_name).strip()
        logger.debug(f"ğŸ§¼ Nom nettoyÃ© : {cleaned}")

        # Extraction du titre et annÃ©e Ã©ventuelle
        match = re.match(r"^(.*?)(?:\s+\((\d{4})\))?$", cleaned)
        if not match:
            raise HTTPException(status_code=400, detail="Format de nom de sÃ©rie invalide")

        base_title = match.group(1).strip()
        year = int(match.group(2)) if match.group(2) else None

        logger.debug(f"ğŸ“¥ Titre brut reÃ§u : {series_folder_name}")
        logger.debug(f"ğŸ§¼ Titre nettoyÃ© transmis Ã  Sonarr : {cleaned}")
        logger.debug(f"ğŸ” Recherche dans Sonarr : base_title='{base_title}' | year={year}")

        # RÃ©cupÃ©ration de la sÃ©rie
        series = sonarr.get_series_by_clean_title(cleaned)
        if not series:
            logger.warning(f"â— Aucune sÃ©rie trouvÃ©e pour : {cleaned}")
            raise HTTPException(status_code=404, detail=f"Aucune sÃ©rie trouvÃ©e avec le nom : {cleaned}")

        series_id = series["id"]
        logger.info(f"ğŸ¯ SÃ©rie trouvÃ©e : {series['title']} â€” ID : {series_id}")

        # RafraÃ®chissement + recherche
        logger.debug(f"ğŸ”„ RafraÃ®chissement de la sÃ©rie ID={series_id}")
        sonarr.refresh_series(series_id)

        await asyncio.sleep(5)

        logger.debug(f"ğŸ” Lancement de la recherche manuelle pour ID={series_id}")
        sonarr.search_missing_episodes(series_id)

        logger.info(f"ğŸ“¥ Recherche d'Ã©pisodes lancÃ©e pour : {series['title']}")

        # VÃ©rification locale aprÃ¨s scan
        await asyncio.sleep(2)
        if symlink_path.exists():
            logger.info("âœ… Le fichier est revenu localement aprÃ¨s scan. Fin normale.")
            return {"message": "Symlink supprimÃ© et fichier revenu aprÃ¨s scan."}

        logger.warning("ğŸš« Fichier toujours manquant aprÃ¨s scan â€” suppression complÃ¨te de la saison")

        # Suppression de tous les .mkv de la saison
        deleted_count = 0

        valid_extensions = {".mkv", ".m4v", ".mp4"}

        deleted_count = 0
        for file in season_dir.iterdir():
                if file.suffix.lower() in valid_extensions and (file.is_symlink() or not file.exists()):
                        try:
                                file.unlink()
                                deleted_count += 1
                                logger.info(f"ğŸ§¹ SupprimÃ© : {file}")
                        except Exception as e:
                                logger.error(f"âŒ Erreur suppression fichier : {e}")

        # Extraction robuste du numÃ©ro de saison
        match = re.search(r"(\d{1,2})", season_dir.name)
        if not match:
            logger.error(f"âŒ NumÃ©ro de saison introuvable dans : {season_dir.name}")
            raise HTTPException(status_code=400, detail="NumÃ©ro de saison introuvable")
        season_number = int(match.group(1))
        logger.debug(f"ğŸ”¢ NumÃ©ro de saison extrait : {season_number}")

        # Appel de lâ€™API POST /delete-sonarr-season
        try:
            async with httpx.AsyncClient(timeout=20.0) as client:
                response = await client.post(
                    "http://localhost:8080/api/v1/symlinks/delete-sonarr-season",
                    params={"series_name": cleaned, "season_number": season_number}
                )
                if response.status_code != 200:
                    logger.error(f"âŒ API delete-sonarr-season a Ã©chouÃ© : {response.text}")
                    raise HTTPException(status_code=500, detail="Ã‰chec suppression saison via delete-sonarr-season")
        except Exception as e:
            logger.error(f"âŒ Erreur appel httpx : {str(e)}")
            raise HTTPException(status_code=500, detail="Erreur lors de l'appel Ã  delete-sonarr-season")

        logger.info("âœ… Suppression saison effectuÃ©e via delete-sonarr-season")
        return {"message": "Symlink supprimÃ©. Saison nettoyÃ©e et supprimÃ©e cÃ´tÃ© Sonarr."}

    except HTTPException as e:
        logger.error(f"ğŸš¨ HTTPException capturÃ©e : {e.detail}")
        raise e
    except Exception as e:
        logger.error("ğŸ’¥ Exception inattendue capturÃ©e", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur interne : {str(e)}")

@router.post("/delete-sonarr-season")
async def delete_sonarr_season(
    series_name: str = Query(..., description="Nom complet de la sÃ©rie"),
    season_number: int = Query(..., description="NumÃ©ro de la saison"),
    sonarr: SonarrService = Depends(SonarrService)
):
    """
    RafraÃ®chit la sÃ©rie et lance une recherche des Ã©pisodes manquants pour la saison donnÃ©e.
    Ã€ utiliser uniquement aprÃ¨s suppression physique des symlinks correspondants.
    """
    logger.info(f"ğŸ” RafraÃ®chissement + recherche pour : {series_name} | Saison {season_number}")

    # Nettoyage lÃ©ger du nom (retrait de {imdb-tt...})
    cleaned_series = re.sub(r'\s*\{imdb-tt\d{7,}\}', '', series_name).strip()

    try:
        # RÃ©cupÃ©ration de la sÃ©rie via Sonarr
        series = sonarr.get_series_by_clean_title(cleaned_series)
        if not series:
            raise HTTPException(status_code=404, detail="SÃ©rie introuvable")

        series_id = series["id"]
        logger.info(f"ğŸ“º SÃ©rie trouvÃ©e : {series['title']} (ID={series_id})")

        # RafraÃ®chissement + recherche
        sonarr.refresh_series(series_id)
        await asyncio.sleep(2)
        sonarr.search_missing_episodes(series_id)

        logger.info(f"âœ… RafraÃ®chissement et recherche lancÃ©s pour {cleaned_series}")
        return {
            "message": f"Recherche relancÃ©e pour la saison {season_number} de {cleaned_series}"
        }

    except Exception as e:
        logger.warning(f"âš ï¸ Erreur Sonarr : {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de l'appel Ã  Sonarr")

@router.post("/delete_broken_sonarr")
async def delete_broken_sonarr_symlinks(
    folder: Optional[str] = None,
    sonarr: SonarrService = Depends(SonarrService)
):
    logger.info("ğŸš€ Suppression en masse des symlinks Sonarr cassÃ©s demandÃ©e")

    if not symlink_store:
        raise HTTPException(status_code=503, detail="Cache vide, lancez un scan d'abord.")

    config = load_config()
    base_links_dir = Path(config.get("links_dirs", ["/"])[0]).resolve()

    # Filtrage initial
    items = symlink_store.copy()
    if folder:
        folder_path = (base_links_dir / folder).resolve()
        items = [i for i in items if i["symlink"].startswith(str(folder_path))]

    # Filtrer uniquement les symlinks cassÃ©s des sÃ©ries
    broken_symlinks = [i for i in items if i["ref_count"] == 0 and "/shows/" in i["symlink"]]
    if not broken_symlinks:
        return {"message": "Aucun symlink cassÃ© Sonarr Ã  supprimer", "deleted": 0}

    logger.info(f"ğŸ” {len(broken_symlinks)} symlinks Sonarr cassÃ©s Ã  traiter")

    deleted_count = 0
    errors = []

    for item in broken_symlinks:
        try:
            symlink_path = Path(item["symlink"])
            if not symlink_path.is_symlink():
                logger.warning(f"â›” Pas un symlink valide : {symlink_path}")
                continue

            # Supprimer le symlink
            symlink_path.unlink()
            logger.success(f"ğŸ—‘ï¸ SupprimÃ© : {symlink_path}")
            deleted_count += 1

            # Extraire dossier sÃ©rie
            series_dir = symlink_path.parent.parent
            raw_name = series_dir.name
            cleaned = clean_series_name(raw_name)

            # Rechercher la sÃ©rie dans Sonarr
            series = sonarr.get_series_by_clean_title(cleaned)
            if not series:
                logger.warning(f"â— Aucune sÃ©rie trouvÃ©e dans Sonarr : {cleaned}")
                continue

            series_id = series["id"]
            logger.info(f"ğŸ“º SÃ©rie Sonarr trouvÃ©e : {series['title']} (ID={series_id})")

            # RafraÃ®chir + rechercher les Ã©pisodes
            sonarr.refresh_series(series_id)
            await asyncio.sleep(2)
            sonarr.search_missing_episodes(series_id)
            logger.info(f"ğŸ“¥ Recherche relancÃ©e pour : {series['title']}")

            # VÃ©rification locale aprÃ¨s scan
            await asyncio.sleep(2)
            season_dir = symlink_path.parent
            valid_extensions = {".mkv", ".mp4", ".m4v"}

            remaining = [
                f for f in season_dir.iterdir()
                if f.suffix.lower() in valid_extensions and f.exists()
            ]

            if not remaining:
                logger.warning("ğŸš« Tous les fichiers sont absents â€” suppression complÃ¨te de la saison")

                # Extraction robuste du numÃ©ro de saison
                match = re.search(r"(\d{1,2})", season_dir.name)
                if match:
                    season_number = int(match.group(1))
                    logger.debug(f"ğŸ”¢ NumÃ©ro de saison extrait : {season_number}")

                    # Appel Ã  lâ€™API delete-sonarr-season
                    try:
                        async with httpx.AsyncClient(timeout=20.0) as client:
                            response = await client.post(
                                "http://localhost:8080/api/v1/symlinks/delete-sonarr-season",
                                params={
                                    "series_name": cleaned,
                                    "season_number": season_number
                                }
                            )
                            if response.status_code != 200:
                                logger.error(f"âŒ Appel Ã  delete-sonarr-season Ã©chouÃ© : {response.text}")
                    except Exception as e:
                        logger.error(f"âŒ Erreur appel delete-sonarr-season : {e}")

        except Exception as e:
            error_msg = f"Erreur {item['symlink']}: {str(e)}"
            logger.error(error_msg, exc_info=True)
            errors.append(error_msg)

    sse_manager.publish_event("symlink_update", json.dumps({"event": "refreshed"}))

    return {
        "message": f"{deleted_count} symlinks Sonarr cassÃ©s supprimÃ©s",
        "deleted": deleted_count,
        "errors": errors
    }

@router.post("/repair-missing-seasons")
async def repair_missing_seasons(
    folder: Optional[str] = None,
    sonarr: SonarrService = Depends(SonarrService)
):
    logger.info("ğŸ› ï¸ RÃ©paration des saisons manquantes demandÃ©e")

    if not symlink_store:
        raise HTTPException(status_code=503, detail="Cache vide, lancez un scan d'abord.")

    config = load_config()
    base_links_dir = Path(config.get("links_dirs", ["/"])[0]).resolve()

    # Filtrage par dossier (si fourni)
    if folder:
        folder_path = (base_links_dir / folder).resolve()
        items = [i for i in symlink_store if i["symlink"].startswith(str(folder_path))]
    else:
        items = symlink_store.copy()

    deleted_count = 0
    errors = []

    try:
        missing_list = sonarr.get_all_series_with_missing_seasons()
    except Exception as e:
        logger.error(f"âŒ Erreur rÃ©cupÃ©ration sÃ©ries : {e}")
        raise HTTPException(status_code=500, detail="Erreur rÃ©cupÃ©ration des sÃ©ries avec saisons manquantes")

    for entry in missing_list:
        series_id = entry["id"]
        series_title = entry["title"]
        missing_seasons = entry["missing_seasons"]

        logger.info(f"ğŸ“º SÃ©rie '{series_title}' - Saisons manquantes : {missing_seasons}")

        # ğŸ” Trouve les symlinks liÃ©s Ã  cette sÃ©rie
        matching_items = [i for i in items if series_title.lower() in i["symlink"].lower()]
        if not matching_items:
            logger.warning(f"âš ï¸ Aucun symlink trouvÃ© pour : {series_title}")
            continue

        for season_num in missing_seasons:
            pattern = f"S{season_num:02}"  # S01, S02, ...
            filtered_symlinks = [
                i for i in matching_items if pattern.lower() in i["symlink"].lower()
            ]

            for item in filtered_symlinks:
                symlink_path = Path(item["symlink"])

                if not str(symlink_path).startswith(str(base_links_dir)):
                    logger.warning(f"â›” Chemin interdit (hors links_dir) : {symlink_path}")
                    continue

                try:
                    if symlink_path.exists() and symlink_path.is_symlink():
                        symlink_path.unlink()
                        logger.success(f"ğŸ—‘ï¸ Symlink supprimÃ© avec succÃ¨s : {symlink_path}")
                        deleted_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ Erreur suppression symlink {symlink_path}: {e}")
                    errors.append(str(symlink_path))

            # ğŸ›°ï¸ Appel API interne pour relancer la recherche manuelle sur la saison
            try:
                async with httpx.AsyncClient(timeout=15.0) as client:
                    resp = await client.post(
                        "http://localhost:8080/api/v1/symlinks/delete-sonarr-season",
                        params={"series_name": series_title, "season_number": season_num}
                    )
                    if resp.status_code != 200:
                        logger.warning(f"âŒ Appel delete-sonarr-season Ã©chouÃ© : {resp.text}")
                        errors.append(f"{series_title} - S{season_num:02}")
            except Exception as e:
                logger.error(f"âŒ Erreur HTTPX : {e}")
                errors.append(f"{series_title} - S{season_num:02}")

    sse_manager.publish_event("symlink_update", json.dumps({"event": "refreshed"}))

    return {
        "message": "Saisons manquantes traitÃ©es",
        "symlinks_deleted": deleted_count,
        "errors": errors
    }
